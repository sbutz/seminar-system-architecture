@inproceedings{alpay2021,
author = {Alpay, Aksel and Heuveline, Vincent},
title = {AdaptiveCpp Stdpar: C++ Standard Parallelism Integrated Into a SYCL Compiler},
year = {2024},
isbn = {9798400717901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648115.3648117},
doi = {10.1145/3648115.3648117},
abstract = {Expressing data parallel programs using C++ standard parallelism is attractive not only due to the simplicity of the model, but also due to its highly idiomatic nature. This programming model, commonly referred to as stdpar, can also be used for accelerator programming by offloading calls to standard algorithms, and is supported by multiple vendors, such as NVIDIA with nvc++, AMD with roc-stdpar, and Intel with the new ICPX -fsycl-pstl-offload flag. We present AdaptiveCpp stdpar, a novel stdpar implementation that is part of the AdaptiveCpp SYCL implementation. AdaptiveCpp stdpar is the very first stdpar implementation to demonstrate performance across GPUs from Intel, NVIDIA and AMD, and allows users to start developing applications using C++ standard algorithms, and then progressively move to SYCL as more control is needed. We find that our solution outperforms all vendor stdpar compilers on HPC GPUs in the majority of tested applications, in some configurations by up to an order of magnitude. Furthermore, we show how AdaptiveCpp outperforms nvc++ in a latency-bound code for all tested problem sizes by up to 80\% on NVIDIA A100 due to novel optimizations. Our stdpar implementation deviates from existing implementations by relying on a tighter integration with compiler and runtime, including e.g. dedicated optimization passes to elide synchronization, automatically prefetching required allocations, and an offloading heuristic.},
booktitle = {Proceedings of the 12th International Workshop on OpenCL and SYCL},
articleno = {5},
numpages = {12},
keywords = {C++, CUDA, GPU, HIP, LLVM, SPIR-V, SYCL, compilers, heterogeneity, parallelism, parallelruntimes, stdpar},
location = {Chicago, IL, USA},
series = {IWOCL '24}
}

@book{reinders2020data,
  title={Data Parallel C++: Mastering DPC++ for Programming of Heterogeneous Systems Using C++ and SYCL},
  author={Reinders, J. and Ashbaugh, B. and Brodman, J. and Kinsner, M. and Pennycook, J. and Tian, X.},
  isbn={9781484255735},
  url={https://books.google.de/books?id=vLI7zAEACAAJ},
  year={2020},
  publisher={Apress}
}

@techreport{SYCL2020,
  author       = {Khronos SYCL Working Group},
  title        = {SYCL 2020 rev 4 Specification},
  year         = {2021},
  type         = {Standard},
  institution  = {Khronos Group, Inc},
  address      = {Beaverton, OR, USA},
  url          = {https://www.khronos.org/registry/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf},
  note         = {Available at: \url{https://www.khronos.org/registry/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf}}
}

@misc{GitAdaptiveCpp,
  author       = {{AdaptiveCpp Contributors}},
  title        = {AdaptiveCpp: Implementation of SYCL and C++ standard parallelism for CPUs and GPUs from all vendors},
  howpublished = {\url{https://github.com/AdaptiveCpp/AdaptiveCpp}},
  note         = {Accessed: 2025-02-02}
}

@article{V'yukova2018,
  title={Support for parallel and concurrent programming in C++},
  author={V’yukova, NI and Galatenko, VA and Samborskii, SV},
  journal={Programming and Computer Software},
  volume={44},
  pages={35--42},
  year={2018},
  publisher={Springer}
}

@manual{NVIDIA2020,
  title        = {C++ Parallel Algorithms},
  author       = {NVIDIA},
  year         = {2020},
  url          = {https://docs.nvidia.com/hpc-sdk/archive/20.7/pdf/hpc207c%2B%2B_par_alg.pdf}
}

@misc{p2300r10,
  title        = {P2300R10: std::execution},
  author       = {Kirk Shoop and Lewis Baker and Lee Howes and Michael Garland and Eric Niebler and Bryce Adelstein Lelbach and Gordon Brown and Michael J. Avermann and Hannes Domani and Maurizio Vitale and Michael Wong},
  year         = {2024},
  note         = {ISO/IEC JTC1/SC22/WG21 Proposal},
  url          = {https://wg21.link/P2300}
}

@techreport{p3024r0,
  title        = {P3024R0: Interface Directions for std::simd},
  author       = {Matthias Kretz},
  year         = {2023},
  institution  = {ISO/IEC JTC1/SC22/WG21},
  url          = {https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3024r0.html}
}

@online{simd_cppreference,
  title        = {std::experimental::simd},
  author       = {cppreference.com},
  year         = {2023},
  url          = {https://en.cppreference.com/w/cpp/experimental/simd},
  note         = {Accessed: 2024-03-01}
}

@inproceedings{10.1145/2509136.2509515,
author = {Meyerovich, Leo A. and Rabkin, Ariel S.},
title = {Empirical analysis of programming language adoption},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509515},
doi = {10.1145/2509136.2509515},
abstract = {Some programming languages become widely popular while others fail to grow beyond their niche or disappear altogether. This paper uses survey methodology to identify the factors that lead to language adoption. We analyze large datasets, including over 200,000 SourceForge projects, 590,000 projects tracked by Ohloh, and multiple surveys of 1,000-13,000 programmers.We report several prominent findings. First, language adoption follows a power law; a small number of languages account for most language use, but the programming market supports many languages with niche user bases. Second, intrinsic features have only secondary importance in adoption. Open source libraries, existing code, and experience strongly influence developers when selecting a language for a project. Language features such as performance, reliability, and simple semantics do not. Third, developers will steadily learn and forget languages. The overall number of languages developers are familiar with is independent of age. Finally, when considering intrinsic aspects of languages, developers prioritize expressivity over correctness. They perceive static types as primarily helping with the latter, hence partly explaining the popularity of dynamic languages.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages \&amp; Applications},
pages = {1–18},
numpages = {18},
keywords = {programming language adoption, survey research},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{usage_of_languages,
author = {Meyerovich, Leo A. and Rabkin, Ariel S.},
title = {Empirical analysis of programming language adoption},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2544173.2509515},
doi = {10.1145/2544173.2509515},
abstract = {Some programming languages become widely popular while others fail to grow beyond their niche or disappear altogether. This paper uses survey methodology to identify the factors that lead to language adoption. We analyze large datasets, including over 200,000 SourceForge projects, 590,000 projects tracked by Ohloh, and multiple surveys of 1,000-13,000 programmers.We report several prominent findings. First, language adoption follows a power law; a small number of languages account for most language use, but the programming market supports many languages with niche user bases. Second, intrinsic features have only secondary importance in adoption. Open source libraries, existing code, and experience strongly influence developers when selecting a language for a project. Language features such as performance, reliability, and simple semantics do not. Third, developers will steadily learn and forget languages. The overall number of languages developers are familiar with is independent of age. Finally, when considering intrinsic aspects of languages, developers prioritize expressivity over correctness. They perceive static types as primarily helping with the latter, hence partly explaining the popularity of dynamic languages.},
journal = {SIGPLAN Not.},
month = oct,
pages = {1–18},
numpages = {18},
keywords = {programming language adoption, survey research}
}

@book{opencl_guide,
  author = {Munshi, Aaftab and Gaster, Benedict and Mattson, Timothy G. and Fung, James and Ginsburg, Dan},
  title = {OpenCL Programming Guide},
  year = {2011},
  isbn = {0321749642},
  publisher = {Addison-Wesley Professional},
  edition = {1st},
  abstract = {Using the new OpenCL (Open Computing Language) standard, you can write applications that access all available programming resources: CPUs, GPUs, and other processors such as DSPs and the Cell/B.E. processor. Already implemented by Apple, AMD, Intel, IBM, NVIDIA, and other leaders, OpenCL has outstanding potential for PCs, servers, handheld/embedded devices, high performance computing, and even cloud systems. This is the first comprehensive, authoritative, and practical guide to OpenCL 1.1 specifically for working developers and software architects. Written by five leading OpenCL authorities, OpenCL Programming Guide covers the entire specification. It reviews key use cases, shows how OpenCL can express a wide range of parallel algorithms, and offers complete reference material on both the API and OpenCL C programming language. Through complete case studies and downloadable code examples, the authors show how to write complex parallel programs that decompose workloads across many different devices. They also present all the essentials of OpenCL software performance optimization, including probing and adapting to hardware. Coverage includes Understanding OpenCLs architecture, concepts, terminology, goals, and rationaleProgramming with OpenCL C and the runtime APIUsing buffers, sub-buffers, images, samplers, and eventsSharing and synchronizing data with OpenGL and Microsofts Direct3DSimplifying development with the C++ Wrapper APIUsing OpenCL Embedded Profiles to support devices ranging from cellphones to supercomputer nodesCase studies dealing with physics simulation; image and signal processing, such as image histograms, edge detection filters, Fast Fourier Transforms, and optical flow; math libraries, such as matrix multiplication and high-performance sparse matrix multiplication; and more}
}

@manual{NVIDIA_CUDA_ProgGuide,
  title        = {CUDA C Programming Guide},
  author       = {NVIDIA},
  year         = {2024},
  url          = {https://docs.nvidia.com/cuda/cuda-c-programming-guide/},
  note         = {Accessed: 2024-03-01}
}

@manual{AMD_ROCm_Docs,
  title        = {ROCm Documentation},
  author       = {Advanced Micro Devices (AMD)},
  year         = {2024},
  url          = {https://rocm.docs.amd.com/en/latest/},
  note         = {Accessed: 2024-03-01}
}
